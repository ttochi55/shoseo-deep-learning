{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "31_Dogs_vs_Cats.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cI4vJCDsV2yQ"
      },
      "source": [
        "# Kaggle Dataset의 전부를 이용한 개, 고양이 구분\n",
        "Dog Image: 12,500개, Cat Image: 12,500개, 총 25,000개\n",
        "- [모두의 딥러닝](https://github.com/Heechul90/Python_Deep_Learning)\n",
        "- <https://github.com/pontorezende/Dogs-vs-Cats-Redux-with-CNN>\n",
        "- <https://www.kaggle.com/sarvajna/dogs-vs-cats-keras-solution>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9y9AVqJ39TwZ",
        "outputId": "5036a3a0-c74c-45ea-970e-5b2c75cd6b88"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jt0-3HKMXdJt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0695d0c7-fc34-4e22-e043-5b0416544ee0"
      },
      "source": [
        "!cp drive/MyDrive/Colab\\ Notebooks/train.zip ."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  train.zip\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of train.zip or\n",
            "        train.zip.zip, and cannot find train.zip.ZIP, period.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7icP0H7TlJGx"
      },
      "source": [
        "# -qq: silent\n",
        "# -d: directory\n",
        "!unzip -qq train.zip -d dogs-vs-cats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvnVVXX_-Brg",
        "outputId": "7b9c5def-5fb4-4033-8167-dbe48c66d9e6"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oy_h0Ah1lOlt"
      },
      "source": [
        "!ls -l dogs-vs-cats/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3KMxD9lUsHq"
      },
      "source": [
        "# Perform the necessary imports.\n",
        "import os, random, cv2\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4LW7IKwmOoO"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6Ls-FfAV8X6"
      },
      "source": [
        "# seed 값 설정\n",
        "seed = 2021\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pwyHX0XWigW"
      },
      "source": [
        "path='dogs-vs-cats/train'"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMDiljg0WijM"
      },
      "source": [
        "## used for resize and in our model\n",
        "ROW, COL = 96, 96\n",
        "\n",
        "dogs, cats = [], []\n",
        "y_dogs, y_cats = [], []"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUvYoIfCWil6"
      },
      "source": [
        "## Definition to load all our dog images\n",
        "def load_dogs():\n",
        "    print('Loading all dog images\\n')\n",
        "    dog_path = os.path.join(path, 'dog*')\n",
        "    for dog_img in glob(dog_path):\n",
        "        dog = cv2.imread(dog_img)\n",
        "        dog = cv2.cvtColor(dog, cv2.COLOR_BGR2GRAY)\n",
        "        dog = cv2.resize(dog, (ROW, COL))\n",
        "        dog = image.img_to_array(dog)\n",
        "        dogs.append(dog)\n",
        "    print('All dog images loaded')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00rGqH1qWiod"
      },
      "source": [
        "## Definition to load all our cat images\n",
        "def load_cats():\n",
        "    print('Loading all cat images\\n')\n",
        "    cat_path = os.path.join(path, 'cat*')\n",
        "    for cat_img in glob(cat_path):\n",
        "        cat = cv2.imread(cat_img)\n",
        "        cat = cv2.cvtColor(cat, cv2.COLOR_BGR2GRAY)\n",
        "        cat = cv2.resize(cat, (ROW, COL))\n",
        "        cat = image.img_to_array(cat)\n",
        "        cats.append(cat)\n",
        "    print('All cat images loaded')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRsMUkAUWirJ"
      },
      "source": [
        "## in case we want to see if our images was saved correctly in arrays we can use those codes\n",
        "def show_dogs():\n",
        "    plt.figure(figsize=(12,4))    \n",
        "    for i in range(5):\n",
        "        plt.subplot(1, 5, i+1)\n",
        "        img = image.array_to_img(random.choice(dogs))\n",
        "        plt.imshow(img, cmap=plt.get_cmap('gray'))\n",
        "        \n",
        "        plt.axis('off')\n",
        "        plt.title(f'Supposed to be a {classes[0]}')        \n",
        "    plt.show()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26E2gYxwWiuS"
      },
      "source": [
        "def show_cats():\n",
        "    plt.figure(figsize=(12,4))\n",
        "    for i in range(5):\n",
        "        plt.subplot(1, 5, i+1)\n",
        "        img = image.array_to_img(random.choice(cats))\n",
        "        plt.imshow(img, cmap=plt.get_cmap('gray'))\n",
        "\n",
        "        plt.axis('off')\n",
        "        plt.title(f'Supposed to be a {classes[1]}')\n",
        "    plt.show()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5GxIXSfWixB"
      },
      "source": [
        "load_dogs()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPieDBM2C-OK"
      },
      "source": [
        "load_cats()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8ifdTu-C-UR"
      },
      "source": [
        "classes = ['dog', 'cat']"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aN5CcEPC-XZ"
      },
      "source": [
        "show_dogs()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lv61cgUFC-aR"
      },
      "source": [
        "show_cats()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeHyMBi1DGAF"
      },
      "source": [
        "## just change the labels for 0 and 1\n",
        "y_dogs = [1 for item in enumerate(dogs)]\n",
        "y_cats = [0 for item in enumerate(cats)]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ku8KvSfjDGC9"
      },
      "source": [
        "## converting everything to Numpy array to fit in our model\n",
        "## them creating a X and target file like we used to see\n",
        "## in Machine and Deep Learning models\n",
        "dogs = np.asarray(dogs).astype('float32') / 255\n",
        "cats = np.asarray(cats).astype('float32') / 255\n",
        "y_dogs = np.asarray(y_dogs).astype('int32')\n",
        "y_cats = np.asarray(y_cats).astype('int32')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuUsVfdGDGF1"
      },
      "source": [
        "X = np.concatenate((dogs, cats), axis=0)\n",
        "y = np.concatenate((y_dogs, y_cats), axis=0)\n",
        "X.shape, y.shape"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfWztA7FDGHS"
      },
      "source": [
        "IMG_CHANNEL = 1\n",
        "BATCH_SIZE = 128\n",
        "N_EPOCH = 30\n",
        "VERBOSE = 2\n",
        "VALIDAION_SPLIT = 0.2\n",
        "OPTIM = Adam()\n",
        "N_CLASSES = len(classes)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3eas34aDGJ4"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, stratify=y, test_size=0.2, random_state=seed\n",
        ")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oyYTiHZDGM5"
      },
      "source": [
        "## One-Hot Encoding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y_train = to_categorical(y_train, N_CLASSES)\n",
        "y_test = to_categorical(y_test, N_CLASSES)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1Vj53AWDVyf"
      },
      "source": [
        "## Here is our model as a CNN\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3,3), padding='same', input_shape=(ROW, COL, IMG_CHANNEL), activation='relu'),\n",
        "    Conv2D(32, (3,3), padding='same', activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2,2)),\n",
        "    Dropout(.25),\n",
        "    Conv2D(64, (3,3), padding='same', activation='relu'),\n",
        "    Conv2D(64, (3,3), padding='same', activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2,2)),\n",
        "    Dropout(.25),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(.5),\n",
        "    Dense(N_CLASSES, activation='softmax')\n",
        "])\n",
        "model.summary()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-w6AvXvDV1R"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', \n",
        "              optimizer=OPTIM, metrics=['accuracy'])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ku17uCyYDV31"
      },
      "source": [
        "## to save checkpoint to use latter\n",
        "modelpath = 'model/dogs_vs_cats_redux_checkpoint.h5'\n",
        "checkpoint = ModelCheckpoint(filepath=modelpath, save_best_only=True, verbose=1)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "He0TosHNDV5w"
      },
      "source": [
        "history = model.fit(X_train, y_train, \n",
        "                    batch_size=BATCH_SIZE, epochs=N_EPOCH, \n",
        "                    validation_split=VALIDAION_SPLIT,\n",
        "                    verbose=VERBOSE, callbacks=[checkpoint])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yq90CxkgDV8B"
      },
      "source": [
        "acc = model.evaluate(X_test, y_test, verbose=2)[1]\n",
        "print('MODEL ACCURACY: %.5f' % acc)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u50xzmqVDg7w"
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "best_model = load_model(modelpath)\n",
        "acc = best_model.evaluate(X_test, y_test, verbose=2)[1]\n",
        "print('Best model accuracy: %.5f' % acc)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mco9NN-PDg-x"
      },
      "source": [
        "# 검증셋\n",
        "y_vloss = history.history['val_loss']\n",
        "y_vacc = history.history['val_accuracy']\n",
        "\n",
        "# 학습셋\n",
        "y_loss = history.history['loss']\n",
        "y_acc = history.history['accuracy']"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZTdmaifDhBy"
      },
      "source": [
        "x_len = np.arange(1, len(y_loss)+1)\n",
        "fig, ax0 = plt.subplots(figsize=(10,8))\n",
        "ax1 = ax0.twinx()\n",
        "ax0.plot(x_len, y_loss, c=\"blue\", label='train set loss')\n",
        "ax0.plot(x_len, y_vloss, c=\"red\", label='valid set loss')\n",
        "ax0.set_ylabel('loss')\n",
        "ax1.plot(x_len, y_acc, c=\"darkgreen\", label='train set acc')\n",
        "ax1.plot(x_len, y_vacc, c=\"magenta\", label='valid set acc')\n",
        "ax1.set_ylabel('accuracy')\n",
        "ax0.set_xlabel('epoch')\n",
        "ax0.legend(loc='lower center')\n",
        "ax1.legend(loc='upper center')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcmEoT0dDqL5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}