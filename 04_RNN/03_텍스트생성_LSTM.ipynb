{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_텍스트생성_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJ5elgCz54YI"
      },
      "source": [
        "# RNN을 이용한 텍스트 생성\n",
        "- '경마장에 있는 말이 뛰고 있다'\n",
        "- '그의 말이 법이다'\n",
        "- '가는 말이 고와야 오는 말이 곱다'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhgNS2aL57AY"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "seed = 2021\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzNXLsc_6vZC"
      },
      "source": [
        "# 3개의 문장을 변수에 저장\n",
        "text=\"\"\"경마장에 있는 말이 뛰고 있다\\n\n",
        "그의 말이 법이다\\n\n",
        "가는 말이 고와야 오는 말이 곱다\\n\"\"\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whDIEcMU63l5",
        "outputId": "9ddeddf3-081a-4b22-d169-017f80196760"
      },
      "source": [
        "# 단어 집합 생성\n",
        "t = Tokenizer()\n",
        "t.fit_on_texts([text])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'가는': 8,\n",
              " '경마장에': 2,\n",
              " '고와야': 9,\n",
              " '곱다': 11,\n",
              " '그의': 6,\n",
              " '뛰고': 4,\n",
              " '말이': 1,\n",
              " '법이다': 7,\n",
              " '오는': 10,\n",
              " '있는': 3,\n",
              " '있다': 5}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yp4zrnVD7xSC",
        "outputId": "4cada12c-d513-40e7-877b-ccce60adcc21"
      },
      "source": [
        "# 단어 집합 크기 설정\n",
        "vocab_size = len(t.word_index) + 1\n",
        "# 케라스 토크나이저의 정수 인코딩은 인덱스가 1부터 시작하지만,\n",
        "# 케라스 원-핫 인코딩에서 배열의 인덱스가 0부터 시작하기 때문에\n",
        "# 배열의 크기를 실제 단어 집합의 크기보다 +1로 생성해야 함\n",
        "print('단어 집합의 크기: %d' % vocab_size)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "단어 집합의 크기: 12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMXMUvS07x0O",
        "outputId": "fad3f19c-fd6b-4591-da7b-7dcef7f27635"
      },
      "source": [
        "sequences = []\n",
        "for line in text.split('\\n'): # \\n을 기준으로 문장 토큰화\n",
        "  encoded = t.texts_to_sequences([line])[0]\n",
        "  for i in range(1, len(encoded)):\n",
        "    sequence = encoded[:i+1]\n",
        "    sequences.append(sequence)\n",
        "\n",
        "print('학습에 사용할 샘플의 개수: %d' % len(sequences))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "학습에 사용할 샘플의 개수: 11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30fF7_CT_ur0",
        "outputId": "bb8373ad-4a0a-47c0-f296-7f9dc1dc29c8"
      },
      "source": [
        "# 모든 샘플에서 길이가 가장 긴 샘플의 길이 출력\n",
        "max_len = max(len(s) for s in sequences)\n",
        "print('샘플의 최대 길이: ', max_len)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "샘플의 최대 길이:  6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogIAuAAN_vBz",
        "outputId": "73e178fe-878a-4577-c7c3-8839938f934c"
      },
      "source": [
        "# 패딩: 문장의 길이를 최대 길이에 맞추어 주는 방법 - 남는 공간에는 0을 할당한다\n",
        "# 전체 샘플의 길이를 6(가장 긴 샘플의 길이)으로 패딩\n",
        "# 'pre'옵션을 주면 앞을 0으로 할당한다\n",
        "sequences = pad_sequences(sequences, maxlen=max_len, padding='pre')\n",
        "sequences[:5]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 2, 3],\n",
              "       [0, 0, 0, 2, 3, 1],\n",
              "       [0, 0, 2, 3, 1, 4],\n",
              "       [0, 2, 3, 1, 4, 5],\n",
              "       [0, 0, 0, 0, 6, 1]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbX54_Fe_vEY",
        "outputId": "8f7a3d89-a7f3-4a25-db5f-41c536361cf6"
      },
      "source": [
        "# 각 샘플의 마지막 단어를 레이블로 분리\n",
        "X = sequences[:, :-1]\n",
        "y = sequences[:, -1]\n",
        "# 리스트의 마지막 값을 제외하고 저장한 것은 X\n",
        "# 리스트의 마지막 값만 저장한 것은 y. 이는 레이블에 해당된다.\n",
        "X[:3]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 2],\n",
              "       [0, 0, 0, 2, 3],\n",
              "       [0, 0, 2, 3, 1]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJpK5OMvBB2D",
        "outputId": "6ce58187-21b5-4f2f-b0e9-c23c333b27af"
      },
      "source": [
        "# 레이블 데이터 y에 대해서 원-핫 인코딩을 수행\n",
        "Y = to_categorical(y, num_classes=vocab_size)\n",
        "Y[:3]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubklSy4j6EX7"
      },
      "source": [
        "## 모델 정의\n",
        "\n",
        "- Embedding\n",
        "- LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjGm3bPO57E9"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Dense, LSTM"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwtUd7jl57H3",
        "outputId": "b522f9bf-7bb5-4919-b064-294ce8cf60d5"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=5, input_length=max_len-1))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dense(units=vocab_size, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 5, 5)              60        \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 32)                4864      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 12)                396       \n",
            "=================================================================\n",
            "Total params: 5,320\n",
            "Trainable params: 5,320\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3AXQXom57Kj"
      },
      "source": [
        "model.compile(\n",
        "    loss='categorical_crossentropy', \n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy'])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5-lkWm857NS"
      },
      "source": [
        "history = model.fit(X, Y, epochs=200, verbose=0)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GMAkWJzGNFN",
        "outputId": "636dc402-e5c8-4afa-e079-ab28ccdf5061"
      },
      "source": [
        "history.history['accuracy'][-1]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7272727489471436"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cV1LN5HGTKo"
      },
      "source": [
        "## 모델 검증"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nbOv9LX57QC"
      },
      "source": [
        "def sentence_generation(model, t, current_word, n):\n",
        "  init_word = current_word\n",
        "  sentence = ''\n",
        "  for _ in range(n):\n",
        "    encoded = t.texts_to_sequences([current_word])[0]\n",
        "    encoded = pad_sequences([encoded], maxlen=5, padding='pre')\n",
        "    # result = model.predict_classes(encoded, verbose=0) # deprecate predict_classes\n",
        "    result = np.argmax(model.predict(encoded), axis=-1)\n",
        "\n",
        "    for word, index in t.word_index.items():\n",
        "      if index == result:\n",
        "        break\n",
        "    current_word = current_word + ' ' + word\n",
        "    sentence = sentence + ' ' + word\n",
        "\n",
        "  sentence = init_word + sentence\n",
        "  return sentence"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQBANiaEaTES"
      },
      "source": [
        "## 모델 변화\n",
        "- Embedding Vector 갯수: [2, 4, 6, 8]\n",
        "- LSTM 노드 갯수: [24, 32]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4kV3zY_JKXh",
        "outputId": "61c39574-0729-4ea3-db6b-1ee1657088e7"
      },
      "source": [
        "def execute_model(n_embed, n_lstm):\n",
        "  model = Sequential()\n",
        "  \n",
        "  model.add(Embedding(input_dim=vocab_size, output_dim=n_embed, input_length=max_len-1))\n",
        "  model.add(LSTM(n_lstm))\n",
        "  model.add(Dense(units=vocab_size, activation='softmax'))\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  \n",
        "  history = model.fit(X, Y, epochs=200, verbose=0)\n",
        "  accuracy = history.history['accuracy'][-1]\n",
        "\n",
        "  print(\"Accuracy: {:.4f}\".format(accuracy))\n",
        "\n",
        "  print(sentence_generation(model, t, '경마장에', 3))\n",
        "  print(sentence_generation(model, t, '그의', 2))\n",
        "  print(sentence_generation(model, t, '가는', 5))\n",
        "\n",
        "for n_embed in [2, 4, 6, 8]:\n",
        "  for n_lstm in [24, 32]:\n",
        "    print(\"===================\")\n",
        "    print(\"n_embed={}\".format(n_embed), \"n_lstm={}\".format(n_lstm))\n",
        "    execute_model(n_embed, n_lstm)\n",
        "    print()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===================\n",
            "n_embed=2 n_lstm=24\n",
            "Accuracy: 0.4545\n",
            "경마장에 말이 말이 말이\n",
            "그의 말이 말이\n",
            "가는 말이 말이 말이 말이 뛰고\n",
            "\n",
            "===================\n",
            "n_embed=2 n_lstm=32\n",
            "Accuracy: 0.5455\n",
            "경마장에 말이 말이 말이\n",
            "그의 말이 말이\n",
            "가는 말이 말이 말이 있다 곱다\n",
            "\n",
            "===================\n",
            "n_embed=4 n_lstm=24\n",
            "Accuracy: 0.5455\n",
            "경마장에 말이 말이 뛰고\n",
            "그의 말이 말이\n",
            "가는 말이 말이 말이 뛰고 있다\n",
            "\n",
            "===================\n",
            "n_embed=4 n_lstm=32\n",
            "Accuracy: 0.6364\n",
            "경마장에 말이 말이 뛰고\n",
            "그의 말이 말이\n",
            "가는 말이 말이 말이 말이 곱다\n",
            "\n",
            "===================\n",
            "n_embed=6 n_lstm=24\n",
            "Accuracy: 0.6364\n",
            "경마장에 말이 말이 뛰고\n",
            "그의 말이 말이\n",
            "가는 말이 말이 말이 있다 있다\n",
            "\n",
            "===================\n",
            "n_embed=6 n_lstm=32\n",
            "Accuracy: 0.7273\n",
            "경마장에 말이 말이 뛰고\n",
            "그의 말이 말이\n",
            "가는 말이 말이 오는 말이 곱다\n",
            "\n",
            "===================\n",
            "n_embed=8 n_lstm=24\n",
            "Accuracy: 0.7273\n",
            "경마장에 말이 말이 뛰고\n",
            "그의 말이 말이\n",
            "가는 말이 말이 오는 곱다 곱다\n",
            "\n",
            "===================\n",
            "n_embed=8 n_lstm=32\n",
            "Accuracy: 0.6364\n",
            "경마장에 말이 말이 뛰고\n",
            "그의 말이 말이\n",
            "가는 말이 말이 오는 말이 곱다\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIBNuzojJKz4"
      },
      "source": [
        ""
      ],
      "execution_count": 23,
      "outputs": []
    }
  ]
}