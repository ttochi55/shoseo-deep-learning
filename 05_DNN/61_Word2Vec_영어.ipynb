{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "61_Word2Vec_영어.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRFHHbeWhtPN"
      },
      "source": [
        "# 영어 Word2Vec 만들기\n",
        "\n",
        "- 영어로 된 코퍼스를 다운받아 전처리를 수행\n",
        "- 전처리한 데이터를 바탕으로 Word2Vec 작업을 진행\n",
        "- [영어/한국어 Word2Vec 실습](https://wikidocs.net/50739)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pjNcGIEd6fi",
        "outputId": "3665da8f-b9a8-44f2-f524-6609636c8939"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUwRrTWMh4IK"
      },
      "source": [
        "import urllib.request\n",
        "import zipfile\n",
        "from lxml import etree\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxHTuaIZiz6U"
      },
      "source": [
        "## 데이터 다운로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IapHmZ8riri-",
        "outputId": "0c90ff98-6153-4b3b-f660-9be5027cc5b2"
      },
      "source": [
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/GaoleMeng/RNN-and-FFNN-textClassification/master/ted_en-20160408.xml\", filename=\"ted_en-20160408.xml\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('ted_en-20160408.xml', <http.client.HTTPMessage at 0x7fe10d553890>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ce3nGz9wis-3"
      },
      "source": [
        "## 훈련 데이터 전처리하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02Wn1Hh1h4LM"
      },
      "source": [
        "targetXML=open('ted_en-20160408.xml', 'r', encoding='UTF8')\n",
        "target_text = etree.parse(targetXML)\n",
        "\n",
        "# xml 파일로부터 <content>와 </content> 사이의 내용만 가져온다.\n",
        "parse_text = '\\n'.join(target_text.xpath('//content/text()'))\n",
        "\n",
        "# 정규 표현식의 sub 모듈을 통해 content 중간에 등장하는 (Audio), (Laughter) 등의 배경음 부분을 제거.\n",
        "# 해당 코드는 괄호로 구성된 내용을 제거.\n",
        "content_text = re.sub(r'\\([^)]*\\)', '', parse_text)\n",
        "\n",
        "# 입력 코퍼스에 대해서 NLTK를 이용하여 문장 토큰화를 수행.\n",
        "sent_text = sent_tokenize(content_text)\n",
        "\n",
        "# 각 문장에 대해서 구두점을 제거하고, 대문자를 소문자로 변환.\n",
        "normalized_text = []\n",
        "for string in sent_text:\n",
        "     tokens = re.sub(r\"[^a-z0-9]+\", \" \", string.lower())\n",
        "     normalized_text.append(tokens)\n",
        "\n",
        "# 각 문장에 대해서 NLTK를 이용하여 단어 토큰화를 수행.\n",
        "result = [word_tokenize(sentence) for sentence in normalized_text]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-aoMyarh4P5",
        "outputId": "58abe8ce-5ec7-480d-f328-3bcb83485062"
      },
      "source": [
        "print('총 샘플의 개수 : {}'.format(len(result)))\n",
        "for line in result[:3]:\n",
        "    print(line)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "총 샘플의 개수 : 273424\n",
            "['here', 'are', 'two', 'reasons', 'companies', 'fail', 'they', 'only', 'do', 'more', 'of', 'the', 'same', 'or', 'they', 'only', 'do', 'what', 's', 'new']\n",
            "['to', 'me', 'the', 'real', 'real', 'solution', 'to', 'quality', 'growth', 'is', 'figuring', 'out', 'the', 'balance', 'between', 'two', 'activities', 'exploration', 'and', 'exploitation']\n",
            "['both', 'are', 'necessary', 'but', 'it', 'can', 'be', 'too', 'much', 'of', 'a', 'good', 'thing']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLRbYsqhjfhz"
      },
      "source": [
        "## Word2Vec 훈련시키기\n",
        "\n",
        "- size = 워드 벡터의 특징 값. 즉, 임베딩 된 벡터의 차원.\n",
        "- window = 컨텍스트 윈도우 크기\n",
        "- min_count = 단어 최소 빈도 수 제한 (빈도가 적은 단어들은 학습하지 않는다.)\n",
        "- workers = 학습을 위한 프로세스 수\n",
        "- sg = 0은 CBOW, 1은 Skip-gram."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyNW1SuEh4R8"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "model = Word2Vec(sentences=result, size=100, window=5, min_count=5, workers=4, sg=0)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jx7idXF5h4Uy",
        "outputId": "1f992bb5-5d8f-4099-823b-bdc2e0c4081b"
      },
      "source": [
        "model_result = model.wv.most_similar(\"man\")\n",
        "print(model_result)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('woman', 0.8646872043609619), ('guy', 0.8039215207099915), ('lady', 0.7677041292190552), ('girl', 0.7556315064430237), ('boy', 0.7543885111808777), ('gentleman', 0.7195479869842529), ('soldier', 0.7041349411010742), ('kid', 0.6970995664596558), ('poet', 0.6769534945487976), ('surgeon', 0.6725988388061523)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EByT4Uvko-f",
        "outputId": "cce74d44-54eb-41c8-c24b-6ef1ccf77a40"
      },
      "source": [
        "# woman = man - boy + girl\n",
        "# topn: result length\n",
        "model.wv.most_similar(positive=['man', 'girl'], negative=['boy'], topn=3)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('woman', 0.8510866165161133),\n",
              " ('lady', 0.7480716109275818),\n",
              " ('guy', 0.7218708992004395)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKkizVJKjs2S"
      },
      "source": [
        "## Word2Vec 모델 저장하고 로드하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "su1UwZfrh4XR"
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "model.wv.save_word2vec_format('eng_w2v') # 모델 저장\n",
        "loaded_model = KeyedVectors.load_word2vec_format(\"eng_w2v\") # 모델 로드"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YM34UwHwh4ZX",
        "outputId": "510c3f78-76c3-40af-e753-a092113a98b5"
      },
      "source": [
        "model_result = loaded_model.most_similar(\"man\")\n",
        "print(model_result)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('woman', 0.8646872043609619), ('guy', 0.8039215207099915), ('lady', 0.7677041292190552), ('girl', 0.7556315064430237), ('boy', 0.7543885111808777), ('gentleman', 0.7195479869842529), ('soldier', 0.7041349411010742), ('kid', 0.6970995664596558), ('poet', 0.6769534945487976), ('surgeon', 0.6725988388061523)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTa9A9brh4b-",
        "outputId": "8ab8c07a-fcbd-462b-b20c-452c993cfc38"
      },
      "source": [
        "!ls -l"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 97816\n",
            "-rw-r--r-- 1 root root 25622357 Feb 24 01:03 eng_w2v\n",
            "drwxr-xr-x 1 root root     4096 Feb 22 14:38 sample_data\n",
            "-rw-r--r-- 1 root root 74533638 Feb 24 00:58 ted_en-20160408.xml\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPPPtdEOh4eL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}